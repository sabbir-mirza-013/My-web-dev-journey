{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sabbir-mirza-013/My-web-dev-journey/blob/main/Breast_cancer_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the dataset**"
      ],
      "metadata": {
        "id": "wL7Dxch7cryM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import base64\n",
        "import zlib\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import Sequence\n",
        "import zipfile\n",
        "from tensorflow.keras import layers, models, losses, metrics, optimizers\n",
        "from PIL import Image\n",
        "import io"
      ],
      "metadata": {
        "id": "EqBNveoc0YZC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_irY8lWenf_I",
        "outputId": "ac1eec74-d0f2-4332-f9f1-1ab2370bcdba"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "ONWM5yE0ZaGu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/Breast Cancer Images dataset/breast-ultrasound-images-dataset.zip'\n",
        "extract_to = '/content/drive/MyDrive/Breast Cancer Images dataset'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "# Check the contents\n",
        "os.listdir(extract_to)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDe9vhyna6QD",
        "outputId": "f3d825cb-ff84-4db9-a7e5-46dd0b2949b6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['breast-ultrasound-images-dataset.zip', 'breast-ultrasound-images-dataset']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "base_path = \"/content/drive/MyDrive/Breast Cancer Images dataset/breast-ultrasound-images-dataset\"\n",
        "img_dir = os.path.join(base_path, \"img\")\n",
        "ann_dir = os.path.join(base_path, \"ann\")\n"
      ],
      "metadata": {
        "id": "Yf5WLIJXczwb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sample Images:\", os.listdir(img_dir)[:3])\n",
        "print(\"Sample Annotations:\", os.listdir(ann_dir)[:3])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2OLe6xId448",
        "outputId": "c03f83a7-e157-4da4-b39a-77960eaff125"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Images: ['benign (101).png', 'benign (10).png', 'benign (100).png']\n",
            "Sample Annotations: ['benign (1).png.json', 'benign (100).png.json', 'benign (104).png.json']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This code defines a custom Keras data generator named BreastCancerDataset for multi-task learning — specifically for breast ultrasound image classification and segmentation. It loads images and their corresponding masks and labels from disk, processes them, and returns them in batches**"
      ],
      "metadata": {
        "id": "OLaivhCR7heS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Map label strings to integer class indices\n",
        "label_map = {\"normal\": 0, \"benign\": 1, \"malignant\": 2}\n"
      ],
      "metadata": {
        "id": "1A5CAScj0kbC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class BreastCancerDataset(Sequence):\n",
        "#     def __init__(self, img_dir, ann_dir, batch_size=8, img_size=256, shuffle=True):\n",
        "#         self.img_dir = img_dir\n",
        "#         self.ann_dir = ann_dir\n",
        "#         self.batch_size = batch_size\n",
        "#         self.img_size = img_size\n",
        "#         self.shuffle = shuffle\n",
        "\n",
        "#         # Match files by name\n",
        "#         self.filenames = [f for f in os.listdir(self.img_dir) if f.endswith(\".png\") or f.endswith(\".jpg\")]\n",
        "#         self.on_epoch_end()\n",
        "\n",
        "#     def __len__(self):\n",
        "#         # Total batches per epoch\n",
        "#         return int(np.ceil(len(self.filenames) / self.batch_size))\n",
        "\n",
        "#     def on_epoch_end(self):\n",
        "#         # Shuffle at epoch end\n",
        "#         if self.shuffle:\n",
        "#             np.random.shuffle(self.filenames)\n",
        "\n",
        "#     def __getitem__(self, index):\n",
        "#         # Get batch file names\n",
        "#         batch_files = self.filenames[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "\n",
        "#         # Allocate batch arrays\n",
        "#         X = np.zeros((len(batch_files), self.img_size, self.img_size, 1), dtype=np.float32)\n",
        "#         Y_mask = np.zeros((len(batch_files), self.img_size, self.img_size, 1), dtype=np.float32)\n",
        "#         Y_label = np.zeros((len(batch_files), 3), dtype=np.float32)  # one-hot\n",
        "\n",
        "#         for i, file in enumerate(batch_files):\n",
        "#             img_path = os.path.join(self.img_dir, file)\n",
        "#             ann_path = os.path.join(self.ann_dir, file.rsplit(\".\", 1)[0] + \".json\")\n",
        "\n",
        "#             # Load and preprocess image\n",
        "#             img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "#             img = cv2.resize(img, (self.img_size, self.img_size))\n",
        "#             img = cv2.GaussianBlur(img, (3, 3), 0)\n",
        "#             img = img.astype(np.float32) / 255.0\n",
        "#             X[i, ..., 0] = img  # add channel dimension\n",
        "\n",
        "#             # Load and decode segmentation mask\n",
        "#             mask = self.decode_mask(ann_path)\n",
        "#             Y_mask[i, ..., 0] = mask\n",
        "\n",
        "#             # Extract and one-hot encode label\n",
        "#             label_str = self.get_label_from_json(ann_path)\n",
        "#             class_idx = label_map[label_str]\n",
        "#             Y_label[i, class_idx] = 1.0\n",
        "\n",
        "#         return X, {\"seg_output\": Y_mask, \"class_output\": Y_label}\n",
        "\n",
        "#     def decode_mask(self, json_path):\n",
        "#         # Decode the bitmap-based mask\n",
        "#         with open(json_path, 'r') as f:\n",
        "#             data = json.load(f)\n",
        "\n",
        "#         obj = data['objects'][0]\n",
        "#         origin_x, origin_y = obj['bitmap']['origin']\n",
        "#         size = data['size']\n",
        "#         H, W = size['height'], size['width']\n",
        "\n",
        "#         compressed_data = base64.b64decode(obj['bitmap']['data'])\n",
        "#         decompressed = zlib.decompress(compressed_data)\n",
        "#         mask_np = np.frombuffer(decompressed, dtype=np.uint8).reshape((H - origin_y, W - origin_x))\n",
        "\n",
        "#         full_mask = np.zeros((H, W), dtype=np.uint8)\n",
        "#         h, w = mask_np.shape\n",
        "#         full_mask[origin_y:origin_y + h, origin_x:origin_x + w] = mask_np\n",
        "\n",
        "#         # Resize mask to match image\n",
        "#         mask_resized = cv2.resize(full_mask, (self.img_size, self.img_size), interpolation=cv2.INTER_NEAREST)\n",
        "#         return mask_resized\n",
        "\n",
        "#     def get_label_from_json(self, json_path):\n",
        "#         with open(json_path, 'r') as f:\n",
        "#             data = json.load(f)\n",
        "#         return data['objects'][0]['classTitle']\n"
      ],
      "metadata": {
        "id": "bVvRQOVS0PkK"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import json\n",
        "# import base64\n",
        "# import zlib\n",
        "# import numpy as np\n",
        "# import cv2\n",
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.utils import Sequence\n",
        "\n",
        "label_map = {\"normal\": 0, \"benign\": 1, \"malignant\": 2}\n",
        "\n",
        "class BreastCancerDataset(Sequence):\n",
        "    def __init__(self, img_dir, ann_dir, batch_size=8, img_size=256, shuffle=True, filenames=None, **kwargs):\n",
        "        super().__init__(**kwargs)  # Fixes the warning about missing super().__init__\n",
        "\n",
        "        self.img_dir = img_dir\n",
        "        self.ann_dir = ann_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.shuffle = shuffle\n",
        "\n",
        "        # Use custom list (e.g., for train/val split) or full list\n",
        "        if filenames:\n",
        "            self.filenames = filenames\n",
        "        else:\n",
        "            self.filenames = [f for f in os.listdir(self.img_dir) if f.endswith(('.png', '.jpg'))]\n",
        "\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.filenames) / self.batch_size))\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.filenames)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_files = self.filenames[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "\n",
        "        X = np.zeros((len(batch_files), self.img_size, self.img_size, 1), dtype=np.float32)\n",
        "        Y_mask = np.zeros((len(batch_files), self.img_size, self.img_size, 1), dtype=np.float32)\n",
        "        Y_label = np.zeros((len(batch_files), 3), dtype=np.float32)\n",
        "\n",
        "        for i, file in enumerate(batch_files):\n",
        "            img_path = os.path.join(self.img_dir, file)\n",
        "            ann_path = os.path.join(self.ann_dir, file + \".json\")  # Fix: .png/.jpg + \".json\"\n",
        "\n",
        "            if not os.path.exists(ann_path):\n",
        "                print(f\"[Warning] Annotation missing for: {file}\")\n",
        "                continue\n",
        "\n",
        "            # --- Image Preprocessing ---\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "            img = cv2.resize(img, (self.img_size, self.img_size))\n",
        "            img = cv2.GaussianBlur(img, (3, 3), 0)\n",
        "            img = img.astype(np.float32) / 255.0\n",
        "            X[i, ..., 0] = img\n",
        "\n",
        "            # --- Mask Decoding ---\n",
        "            mask = self.decode_mask(ann_path)\n",
        "            Y_mask[i, ..., 0] = mask\n",
        "\n",
        "            # --- Label Extraction ---\n",
        "            label_str = self.get_label_from_json(ann_path)\n",
        "            class_idx = label_map[label_str]\n",
        "            Y_label[i, class_idx] = 1.0\n",
        "\n",
        "        return X, {\"seg_output\": Y_mask, \"class_output\": Y_label}\n",
        "\n",
        "\n",
        "\n",
        "    def decode_mask(self, json_path):\n",
        "        with open(json_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        size = data['size']\n",
        "        H, W = size['height'], size['width']\n",
        "\n",
        "        # Case: no mask present (e.g., normal case)\n",
        "        if not data['objects']:\n",
        "            return np.zeros((self.img_size, self.img_size), dtype=np.float32)\n",
        "\n",
        "        obj = data['objects'][0]\n",
        "        origin_x, origin_y = obj['bitmap']['origin']\n",
        "\n",
        "        # Decode bitmap image from base64+zlib into raw bytes\n",
        "        compressed_data = base64.b64decode(obj['bitmap']['data'])\n",
        "        decompressed = zlib.decompress(compressed_data)\n",
        "\n",
        "        # Decode the raw bytes into a PIL image, then into NumPy array\n",
        "        mask_img = Image.open(io.BytesIO(decompressed)).convert('L')\n",
        "        mask_np = np.array(mask_img)\n",
        "\n",
        "        # Create full-size mask and paste the small mask into it\n",
        "        full_mask = np.zeros((H, W), dtype=np.uint8)\n",
        "        h, w = mask_np.shape\n",
        "        full_mask[origin_y:origin_y + h, origin_x:origin_x + w] = mask_np\n",
        "\n",
        "        # Resize to match input size (256x256)\n",
        "        resized_mask = cv2.resize(full_mask, (self.img_size, self.img_size), interpolation=cv2.INTER_NEAREST)\n",
        "        # return resized_mask.astype(np.float32)\n",
        "        return (resized_mask > 127).astype(np.float32)  # ensure binary\n",
        "\n",
        "\n",
        "\n",
        "    def get_label_from_json(self, json_path):\n",
        "        with open(json_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        if data.get('objects') and 'classTitle' in data['objects'][0]:\n",
        "            return data['objects'][0]['classTitle']\n",
        "\n",
        "        # Default label if not found\n",
        "        return \"normal\"\n",
        "\n"
      ],
      "metadata": {
        "id": "n0pgLuWpLvHr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Design: Multitask U-Net**"
      ],
      "metadata": {
        "id": "1G_fKnu8FnRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, losses, metrics, optimizers\n",
        "\n",
        "IMG_SIZE = 256\n",
        "NUM_CLASSES = 3\n",
        "\n",
        "# Dice Loss\n",
        "# def dice_loss(y_true, y_pred, smooth=1e-6):\n",
        "#     y_true_f = tf.reshape(y_true, [-1])\n",
        "#     y_pred_f = tf.reshape(y_pred, [-1])\n",
        "#     intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "#     return 1 - (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred, smooth=1e-6):\n",
        "    # Ensure predictions are float32\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_pred = tf.cast(y_pred, tf.float32)\n",
        "\n",
        "    # Clip predictions to prevent log(0) or NaNs\n",
        "    y_pred = tf.clip_by_value(y_pred, 1e-7, 1.0)\n",
        "\n",
        "    # Flatten per sample\n",
        "    y_true_flat = tf.reshape(y_true, [tf.shape(y_true)[0], -1])\n",
        "    y_pred_flat = tf.reshape(y_pred, [tf.shape(y_pred)[0], -1])\n",
        "\n",
        "    intersection = tf.reduce_sum(y_true_flat * y_pred_flat, axis=1)\n",
        "    denominator = tf.reduce_sum(y_true_flat + y_pred_flat, axis=1)\n",
        "\n",
        "    dice = (2. * intersection + smooth) / (denominator + smooth)\n",
        "    return 1 - tf.reduce_mean(dice)\n",
        "\n",
        "\n",
        "\n",
        "# U-Net Encoder Block\n",
        "def conv_block(x, filters):\n",
        "    x = layers.Conv2D(filters, 3, padding='same', activation='relu')(x)\n",
        "    x = layers.Conv2D(filters, 3, padding='same', activation='relu')(x)\n",
        "    return x\n",
        "\n",
        "# Build Multitask U-Net Model\n",
        "def build_multitask_unet(input_shape=(IMG_SIZE, IMG_SIZE, 1)):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    c1 = conv_block(inputs, 64)\n",
        "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = conv_block(p1, 128)\n",
        "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = conv_block(p2, 256)\n",
        "    p3 = layers.MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    c4 = conv_block(p3, 512)\n",
        "    p4 = layers.MaxPooling2D((2, 2))(c4)\n",
        "\n",
        "    # Bottleneck\n",
        "    bn = conv_block(p4, 1024)\n",
        "\n",
        "    # Segmentation Decoder\n",
        "    u1 = layers.Conv2DTranspose(512, 2, strides=(2, 2), padding='same')(bn)\n",
        "    u1 = layers.concatenate([u1, c4])\n",
        "    c5 = conv_block(u1, 512)\n",
        "\n",
        "    u2 = layers.Conv2DTranspose(256, 2, strides=(2, 2), padding='same')(c5)\n",
        "    u2 = layers.concatenate([u2, c3])\n",
        "    c6 = conv_block(u2, 256)\n",
        "\n",
        "    u3 = layers.Conv2DTranspose(128, 2, strides=(2, 2), padding='same')(c6)\n",
        "    u3 = layers.concatenate([u3, c2])\n",
        "    c7 = conv_block(u3, 128)\n",
        "\n",
        "    u4 = layers.Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(c7)\n",
        "    u4 = layers.concatenate([u4, c1])\n",
        "    c8 = conv_block(u4, 64)\n",
        "\n",
        "    seg_output = layers.Conv2D(1, (1, 1), activation='sigmoid', name='seg_output')(c8)\n",
        "\n",
        "    # Classification Head\n",
        "    gap = layers.GlobalAveragePooling2D()(bn)\n",
        "    dense1 = layers.Dense(128, activation='relu')(gap)\n",
        "    dropout = layers.Dropout(0.5)(dense1)\n",
        "    class_output = layers.Dense(NUM_CLASSES, activation='softmax', name='class_output')(dropout)\n",
        "\n",
        "    model = models.Model(inputs, outputs=[seg_output, class_output])\n",
        "    return model\n",
        "\n",
        "# Build model\n",
        "model = build_multitask_unet()\n",
        "\n",
        "# Loss functions and weights\n",
        "losses_dict = {\n",
        "    'seg_output': dice_loss,\n",
        "    'class_output': 'categorical_crossentropy'\n",
        "}\n",
        "loss_weights = {\n",
        "    'seg_output': 0.5,\n",
        "    'class_output': 0.5\n",
        "}\n",
        "\n",
        "# Compile model\n",
        "# model.compile(\n",
        "#     optimizer=optimizers.Adam(learning_rate=1e-4),\n",
        "#     loss=losses_dict,\n",
        "#     loss_weights=loss_weights,\n",
        "#     metrics={\n",
        "#         'seg_output': [tf.keras.metrics.MeanIoU(num_classes=2)],\n",
        "#         'class_output': ['accuracy']\n",
        "#     }\n",
        "# )\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "    loss={'seg_output': dice_loss, 'class_output': 'categorical_crossentropy'},\n",
        "    loss_weights={'seg_output': 0.5, 'class_output': 0.5},\n",
        "    metrics={'seg_output': [tf.keras.metrics.MeanIoU(num_classes=2)], 'class_output': ['accuracy']}\n",
        ")\n",
        "\n",
        "\n",
        "# model.summary()\n"
      ],
      "metadata": {
        "id": "0knf3rxr0pkS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training the Multitask U-Net**"
      ],
      "metadata": {
        "id": "CXCXVyeFGCRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Import and Configure Callbacks\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, verbose=1),\n",
        "    ModelCheckpoint(\"best_model.h5\", save_best_only=True, monitor=\"val_loss\", verbose=1)\n",
        "]\n"
      ],
      "metadata": {
        "id": "Z__TK9LYFfGy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train/Validation Split\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "all_files = [f for f in os.listdir(img_dir) if f.endswith(\".png\") or f.endswith(\".jpg\")]\n",
        "train_files, val_files = train_test_split(all_files, test_size=0.2, random_state=42)\n",
        "\n",
        "train_gen = BreastCancerDataset(img_dir, ann_dir, batch_size=8, img_size=256)\n",
        "train_gen.filenames = train_files\n",
        "\n",
        "val_gen = BreastCancerDataset(img_dir, ann_dir, batch_size=8, img_size=256, shuffle=False)\n",
        "val_gen.filenames = val_files\n",
        "\n"
      ],
      "metadata": {
        "id": "PrP28SbWGBsC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train the Model\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=30,\n",
        "    callbacks=callbacks\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWGplb76GWYZ",
        "outputId": "2d28a85a-72f9-42cb-8329-2b450e953658"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m18/78\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m56:08\u001b[0m 56s/step - class_output_accuracy: 0.5495 - class_output_loss: 1.0712 - loss: 0.9738 - seg_output_loss: 0.8763 - seg_output_mean_io_u: 0.4573"
          ]
        }
      ]
    }
  ]
}